import os
import requests
import re
from urllib import request
import nltk
import string
from nltk.stem import WordNetLemmatizer

title = 'Ulysses'
author = 'James Joyce'
url = 'https://www.gutenberg.org/files/4300/4300-0.txt'
path = '/Users/renato/PycharmProjects/CLProject/corpus/'


def find_text(raw):
    pass


def text_from_gutenberg(title, author, url, path='/Users/renato/PycharmProjects/CLProject/corpus/', return_raw=False,
                        return_tokens=False):
    # Convert inputs to lowercase
    title = title.lower()
    author = title.lower()

    # Check if the file is stored locally
    filename = '/Users/renato/PycharmProjects/CLProject/corpus/' + title
    if os.path.isfile(filename) and os.stat(filename).st_size != 0:
        print("{title} file already exists".format(title=title))
        print(filename)
        with open(filename, 'r') as f:
            raw = f.read()

    else:
        print("{title} file does not already exist. Grabbing from Project Gutenberg".format(title=title))
        response = request.urlopen(url)
        raw = response.read().decode('utf-8-sig')
        print("Saving {title} file".format(title=title))
        with open(filename, 'w') as outfile:
            outfile.write(raw)

    if return_raw:
        return raw

    # Option to return tokens
    if return_tokens:
        return nltk.word_tokenize(find_text(raw))

    else:
        return find_beginning_and_end(raw)


def find_beginning_and_end(raw):
    '''
    This function serves to find the text within the raw data provided by Project Gutenberg
    '''

    start_regex = '\*\*\*\s?START OF TH(IS|E) PROJECT GUTENBERG EBOOK.*\*\*\*'
    draft_start_position = re.search(start_regex, raw)
    begining = draft_start_position.end()

    if re.search(title.lower(), raw[draft_start_position.end():].lower()):
        title_position = re.search(title.lower(), raw[draft_start_position.end():].lower())
        begining += title_position.end()
        # If the title is present, check for the author's name as well
        if re.search(author.lower(), raw[draft_start_position.end() + title_position.end():].lower()):
            author_position = re.search(author.lower(), raw[draft_start_position.end() + title_position.end():].lower())
            begining += author_position.end()

    end_regex = 'end of th(is|e) project gutenberg ebook'
    end_position = re.search(end_regex, raw.lower())

    text = raw[begining:end_position.start()]

    return text

def preprocessing(text):
    lower_text = text.lower()
    no_punct_corpus = lower_text.translate(str.maketrans("", "", string.punctuation))
    no_number_corpus = re.sub(r'\d+', '', no_punct_corpus)
    tokenized_corpus = nltk.word_tokenize(no_number_corpus)
    lemmatizer = WordNetLemmatizer()
    lemmatized_corpus = " ".join([lemmatizer.lemmatize(word) for word in tokenized_corpus])

    return lemmatized_corpus
    
book_info = [
	('My Bondage and My Freedom', 'Frederick Douglass', 'https://www.gutenberg.org/cache/epub/202/pg202.txt'),
	('Abolition Fanaticism in New York', 'Frederick Douglass', 'https://www.gutenberg.org/cache/epub/34915/pg34915.txt'),
	('Why is the Negro Lynched?', 'Frederick Douglass', 'https://www.gutenberg.org/files/59116/59116-0.txt'),
    ('Three addresses on the relations subsisting between the white and colored people', 'Frederick Douglass', 'https://www.gutenberg.org/cache/epub/67919/pg67919.txt'),
    ('Narrative of the life of Frederick Douglass: an American slave', 'Frederick Douglass', 'https://www.gutenberg.org/files/23/23-0.txt'),
]

path = '/Users/renato/PycharmProjects/CLProject/corpus/'

for title, author, url in book_info:
    processed_text = preprocessing(text_from_gutenberg(title, author, url))
    filename = f"{path}lemmatized_{title.lower().replace('-', '')}.txt"
    with open(filename, "w") as f:
        f.write(processed_text)

    lemmatized_cs = preprocessing(processed_text)
    with open("lemmatized_corpus.txt", "w") as f:
        f.write(str(lemmatized_cs))
    print(lemmatized_cs)
    
book_info = [
	('Moby Dick', 'Herman Melville', 'https://www.gutenberg.org/cache/epub/2489/pg2489.txt'),

	('I and my chimney', 'Herman Melville', 'https://www.gutenberg.org/cache/epub/2694/pg2694.txt'),

	('Omoo: Adventures in the South Seas', 'Herman Melville', 'https://www.gutenberg.org/cache/epub/4045/pg4045.txt'),

    ('White-Jacket', 'Herman Melville', 'https://www.gutenberg.org/cache/epub/10712/pg10712.txt'),

    ('Bartleby, The Scrivener', 'Herman Melville', 'https://www.gutenberg.org/files/23/23-0.txt'),

    ('Mardi: and A Voyage Thither', 'Herman Melville', 'https://www.gutenberg.org/cache/epub/13720/pg13720.txt'),

    ('Israel Potter', 'Herman Melville', 'https://www.gutenberg.org/cache/epub/13721/pg13721.txt'),

    ('The Piazza Tales', 'Herman Melville', 'https://www.gutenberg.org/cache/epub/15422/pg15422.txt'),

    ('The Confidence-Man', 'Herman Melville', 'https://www.gutenberg.org/cache/epub/15859/pg15859.txt'),

    ('Pierre; or The Ambiguities', 'Herman Melville', 'https://www.gutenberg.org/cache/epub/21816/pg21816.txt'),

    ('Battle-Pieces and Aspects of the War', 'Herman Melville', 'https://www.gutenberg.org/cache/epub/34970/pg34970.txt'),

]

path = '/Users/renato/PycharmProjects/CLProject/corpus/'

for title, author, url in book_info:
    processed_text = preprocessing(text_from_gutenberg(title, author, url))
    filename = f"{path}lemmatized_{title.lower().replace('-', '')}.txt"
    with open(filename, "w") as f:
        f.write(processed_text)

    lemmatized_cs = preprocessing(processed_text)
    with open("lemmatized_corpus.txt", "w") as f:
        f.write(str(lemmatized_cs))
    print(lemmatized_cs)
