import os
import requests
import re
from urllib import request
import string
import nltk
from nltk.stem import WordNetLemmatizer
nltk.download('wordnet')
import spacy

#WHAT IT'S NOT WORKING OR COULD BE CHANGES: (1) LEMMATIZATION (POS SHOULD BE INCLUDED); (2) PATH (WE HAVE TO CHANGE MANUALLY IT, COULD BE DONE AUTOMATICALLY)

#CHANGE THESE INFORMATIONS EVERY TIME FOR DEVELOPING A SINGLE TEXT
title = 'The Works of Edgar Allan Poe, Volume 3'
author = 'Edgar Allan Poe'
url = 'https://www.gutenberg.org/files/2149/2149-0.txt'
path = '/Users/renato/PycharmProjects/CLProject/corpus/'


def find_text(raw):
    pass


def text_from_gutenberg(title, author, url, path='/Users/renato/PycharmProjects/CLProject/corpus/', return_raw=False,
                        return_tokens=False):
    # Convert inputs to lowercase
    title = title.lower()
    author = author.lower()

    # Check if the file is stored locally
    filename = '/Users/renato/PycharmProjects/CLProject/corpus/' + title
    if os.path.isfile(filename) and os.stat(filename).st_size != 0:
        print("{title} file already exists".format(title=title))
        print(filename)
        with open(filename, 'r') as f:
            raw = f.read()

    else:
        print("{title} file does not already exist. Grabbing from Project Gutenberg".format(title=title))
        response = request.urlopen(url)
        raw = response.read().decode('utf-8-sig')
        print("Saving {title} file".format(title=title))
        with open(filename, 'w') as outfile:
            outfile.write(raw)

    if return_raw:
        return raw

    # Option to return tokens
    if return_tokens:
        return nltk.word_tokenize(find_text(raw))

    else:
        return raw


def find_beginning_and_end(raw):
    '''
    This function serves to find the text within the raw data provided by Project Gutenberg
    '''

    start_regex = '\*\*\*\s?START OF TH(IS|E) PROJECT GUTENBERG EBOOK.*\*\*\*'
    draft_start_position = re.search(start_regex, raw)
    beginning = draft_start_position.end()

    if re.search(title, raw[draft_start_position.end():].lower()):
        title_position = re.search(title.lower(), raw[draft_start_position.end():].lower())
        beginning += title_position.end()
        # If the title is present, check for the author's name as well
        if re.search(author.lower(), raw[draft_start_position.end() + title_position.end():].lower()):
            author_position = re.search(author.lower(), raw[draft_start_position.end() + title_position.end():].lower())
            beginning += author_position.end()

    end_regex = 'end of th(is|e) project gutenberg ebook'
    end_position = re.search(end_regex, raw.lower())

    text = raw[beginning:end_position.start()]

    return text


def preprocessing(text):
    lower_text = text.lower()
    no_punct_corpus = lower_text.translate(str.maketrans("", "", string.punctuation))
    no_number_corpus = re.sub(r'\d+', '', no_punct_corpus)
    no_number_corpus = str(no_number_corpus)
    tokenized_corpus = nltk.word_tokenize(no_number_corpus)
    lemmatizer = WordNetLemmatizer()
    lemmatized_corpus = " ".join(lemmatizer.lemmatize(word) for word in tokenized_corpus)

    return lemmatized_corpus


poe1_text = preprocessing(text_from_gutenberg(title, author, url))

filename = f"{path}lemmatized_{title.lower().replace('-', '')}.txt"
with open(filename, "w") as f:
    f.write(poe1_text)
    
#FOR LISTS    
 book_info = [
	('Love Letters of Nathaniel Hawthorne, Volume I (of 2)', 'Nathaniel Hawthorne', 'https://www.gutenberg.org/cache/epub/41309/pg41309.txt'),

	('The Snow-Imag', 'Nathaniel Hawthorne', 'https://www.gutenberg.org/cache/epub/30376/pg30376.txt'),

	('The Scarlet Letter', 'Nathaniel Hawthorne', 'https://www.gutenberg.org/cache/epub/33/pg33.txt'),

    ('Love Letters of Nathaniel Hawthorne, Volume 2 (of 2)', 'Nathaniel Hawthorne', 'https://www.gutenberg.org/cache/epub/41368/pg41368.txt'),

    ('The House of the Seven Gables', 'Nathaniel Hawthorne', 'https://www.gutenberg.org/files/77/77-0.txt'),

    ('In colonial days', 'Nathaniel Hawthorne', 'https://www.gutenberg.org/files/64944/64944-0.txt'),

    ('True Stories of History and Biography', 'Nathaniel Hawthorne', 'https://www.gutenberg.org/files/15697/15697-0.txt'),

    ('The Miraculous Pitcher', 'Nathaniel Hawthorne', 'https://www.gutenberg.org/files/9258/9258-0.txt'),

    ('The Three Golden Apples', 'Nathaniel Hawthorne', 'https://www.gutenberg.org/files/9257/9257-0.txt'),

    ('The Paradise of Childrens', 'Nathaniel Hawthorne', 'https://www.gutenberg.org/files/9256/9256-0.txt')
]

path = '/Users/renato/PycharmProjects/CLProject/corpus/'

for title, author, url in book_info:
    processed_text = preprocessing(text_from_gutenberg(title, author, url))
    filename = f"{path}lemmatized_{title.lower().replace('-', '')}.txt"
    with open(filename, "w") as f:
        f.write(processed_text)
